# Project Instructions

## Project Overview
- **Title:** Spectrally Adaptive Mirror Descent with Streaming Sketches (SAMD-SS)
- **Objective:** Deliver production-quality Python code and experiments that substantiate every theoretical claim in *Spectrally Adaptive Mirror Descent with Streaming Sketches: Instance-Optimal Regret and Fast Rates*.
- **Principles:** Prioritise correctness, determinism, and traceability. Each claim in the paper must map to a reproducible experiment, metric, or inequality check in this repository.

---

## 1. Scope & Acceptance Criteria
1. Implement the SAMD-SS optimizer that couples mirror descent with a streaming sketch-based metric.
2. Provide baselines: SGD, AdaGrad (diag + full for tractable dimensions), and ONS-Diag. Full-matrix methods are only required when dimensions are small enough for CPU-only execution.
3. Supply synthetic & real-data experiments validating the paper�s four pillars:
   - **Elliptical potential**: \(S_T = \sum_{t=1}^{T} g_t^\top H_t^{-1} g_t \le \frac{2}{1-\epsilon} \log \frac{\det(\lambda I + G_T)}{\det(\lambda I)}\).
   - **Instance-dependent regret:** \(\mathrm{Reg}_T(x^\star) \le D \sqrt{\frac{2\lambda}{1-\epsilon} \log \frac{\det(\lambda I + G_T)}{\det(\lambda I)}}\).
   - **Fast rates:** Under strong convexity with \(\eta_t = 1/(\alpha t)\) the regret exhibits \(\mathcal{O}(\log T)\) growth.
   - **Sketch inflation:** Empirically verify that inflation tracks \(1/(1-\widehat{\epsilon}_{\text{ridge}})\) as the sketch size varies.
4. Produce a single deterministic Jupyter notebook that:
   - Runs the full pipeline with fixed seeds.
   - Regenerates every figure/table into rtifacts/.
   - Emits explicit pass/fail checks for each bound.
   - Exports LaTeX-ready tables and PDF figures.
5. Ship unit tests + numerical sanity checks that must pass before the notebook is executed.
6. Reproducibility requirements:
   - One pinned environment.yml.
   - A top-level 
un_all.sh that seeds, runs tests, sweeps configs, and builds notebook outputs.

**Any missing acceptance item is an automatic failure.**

---

## 2. Repository Layout
.
├── environment.yml
├── README.md
├── INSTRUCTION.md
├── run_all.sh
├── src/
│   ├── algorithms/
│   │   ├── samd_ss.py
│   │   ├── sgd.py
│   │   ├── adagrad_diag.py
│   │   ├── adagrad_full.py
│   │   └── ons_diag.py
│   ├── sketches/
│   │   ├── frequent_directions.py
│   │   ├── oja_sketch.py
│   │   └── randomized_svd_stream.py
│   ├── data/
│   │   ├── synthetic.py
│   │   └── real.py
│   ├── losses/
│   │   ├── squared.py
│   │   └── logistic.py
│   ├── metrics/
│   │   ├── regret.py
│   │   ├── logdet.py
│   │   ├── stability.py
│   │   └── complexity.py
│   ├── utils/
│   │   ├── config.py
│   │   ├── logging.py
│   │   ├── linalg.py
│   │   ├── projections.py
│   │   ├── reproducibility.py
│   │   └── timers.py
│   └── experiments/
│       ├── run_experiment.py
│       ├── sweep.py
│       └── configs/
│           ├── 01_effective_dimension.yaml
│           ├── 02_sketch_inflation.yaml
│           ├── 03_fast_rates.yaml
│           ├── 04_stability_generalization.yaml
│           └── 05_large_scale.yaml
├── tests/
│   ├── test_algorithms.py
│   ├── test_sketches.py
│   ├── test_metrics.py
│   └── test_sanity.py
├── artifacts/
│   ├── logs/
│   ├── figures/
│   └── tables/
└── notebooks/
    └── main_experiments.ipynb

---

## 3. Environment & Tooling
- Target platform: Linux x86_64 CPU (code must not silently rely on GPUs).
- Provide a single environment.yml with pinned versions (Python 3.10, NumPy 1.26, SciPy 1.11, scikit-learn 1.4, matplotlib 3.8, pandas 2.2, numba 0.58, tqdm 4.66, jupyterlab 4.2, ipywidgets 8.1, pytest 8.x, psutil 5.9, etc.).
- 
un_all.sh must:
  1. Set deterministic seeds (PYTHONHASHSEED, 
andom, NumPy RNG).
  2. Run the pytest suite.
  3. Launch the config sweep (CPU only).
  4. Execute the notebook with Papermill to regenerate plots/tables.
  5. Store every artifact under rtifacts/.

---

## 4. Mathematical Objects
Let \(g_t\) be the gradient/subgradient observed at step \(t\).

| Object                | Definition                                                                                                                       |
| --------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| Cumulative covariance | \(G_t = \sum_{s=1}^{t} g_s g_s^\top\)                                                                                            |
| Metric                | \(H_t = \lambda I + \widetilde{G}_{t-1}\)                                                                                        |
| Elliptical term       | \(q_t = g_t^\top H_t^{-1} g_t\)                                                                                                  |
| Potential             | \(\Phi_T(\lambda) = \log \frac{\det(\lambda I + G_T)}{\det(\lambda I)}\)                                                         |
| Effective dimension   | \(d_{\mathrm{eff}}(\lambda; G_T) = \mathrm{tr}\big(G_T(G_T + \lambda I)^{-1}\big)\)                                              |
| Sketch inflation      | \(\widehat{\epsilon}_{\mathrm{ridge}} = \frac{\lVert \widetilde{G}_T - G_T \rVert_2}{\lambda + \lambda_{\min}(G_T)} \in [0, 1)\) |

---

## 5. Algorithms & Interfaces
### 5.1 SAMD-SS (primary method)
- File: src/algorithms/samd_ss.py.
- Interface:
  `python
  class SAMDSS:
      def __init__(self, dim, lambda_ridge, step_schedule, sketch_backend,
                   sketch_kwargs, constraint=None, alpha_strong_convexity=None): ...
      def reset(self, x0=None, rng=None): ...
      def step(self, grad, t): ...
      def get_state(self): ...
  `
- Requirements:
  - Streaming sketch exposes update(g) and actor() or metric().
  - Use Woodbury identity to apply \(H_t^{-1}\) with cost \(\mathcal{O}(dr + r^3)\).
  - Optional constraint: e.g., projection onto an \(\ell_2\) ball.
  - Track \(q_t\), cumulative potential, per-step LR, and sketch inflation metrics.
  - Provide compatibility wrapper for the legacy .update(w, g) call used by the experiment runner.

### 5.2 Baselines
- SGD with optional momentum.
- AdaGrad-Diag.
- AdaGrad-Full (only when dimension \(\le\) a few hundred).
- ONS-Diag.

### 5.3 Sketch Backends
- Frequent Directions, Oja, Randomized SVD streaming sketches, each with:
  - Deterministic reset.
  - update(grad).
  - actor() returning \(B_t\) such that \(B_t B_t^\top = \widetilde{G}_t\).
  - metric() convenience when dense matrices are acceptable.

---

## 6. Data, Losses & Metrics
- src/data/synthetic.py: regression/logistic generators that return datasets + ground-truth parameters for reference.
- src/data/real.py: deterministic wrappers around scikit-learn datasets (e.g., Breast Cancer) with train/test splits.
- Losses: squared + logistic, each exposing .loss(weights, X, y) and .grad(...) with optional \(\ell_2\) regularisation.
- Metrics (src/metrics/):
  - logdet.py: stable logarithmic determinant and elliptical inequality checks.
  - 
egret.py: instance-dependent regret bound evaluation.
  - stability.py: path length + generalisation gap proxies.
  - complexity.py: timing/memory trackers.

---

## 7. Experiment Orchestration
- src/experiments/run_experiment.py:
  - Loads YAML configs, seeds RNG, prepares dataset + optimizer + loss.
  - Supports mini-batching with deterministic permutations.
  - Logs \(q_t\), log-det terms, regret checks, and saves JSON summaries in rtifacts/logs/.
- src/experiments/sweep.py:
  - Iterates over configs/*.yaml, runs each experiment, and aggregates summaries into rtifacts/tables/sweep_summary.json.
- Config templates must cover:
  1. Effective dimension study (varying \(\lambda\), dataset condition numbers).
  2. Sketch inflation vs. rank (FrequentDirections, Oja, Randomized SVD).
  3. Fast rates under strong convexity (synthetic + real logistic regression).
  4. Stability/generalisation (train/test gaps with logistic loss).
  5. Large-scale baseline (e.g., SGD on high-dimensional synthetic regression).

Each config should specify seeds, domain diameters, constraint radii, sketch ranks, and step schedules.

---

## 8. Notebook & Artifacts
- 
otebooks/main_experiments.ipynb must:
  - Consume rtifacts/tables/sweep_summary.json.
  - Produce every figure/table referenced in the paper.
  - Emit pass/fail flags for all inequalities.
  - Save static assets (PNG/PDF + LaTeX tables) to rtifacts/figures/ and rtifacts/tables/.
- All plots/tables should be versioned outputs�never manual screenshots.

---

## 9. Testing & Validation
1. pytest -q must pass before any sweep or notebook run.
2. Include sanity/integration tests:
   - Finite updates and conditioning checks for optimizers/sketches.
   - Numerical log-det and regret bound smoke tests.
   - End-to-end SAMD-SS run on a toy regression task.
3. CI Philosophy:
   - Prefer deterministic assertions over tolerances whenever possible.
   - Keep runtimes reasonable (<1 minute locally).

---

## 10. Deliverables Checklist
- [ ] environment.yml (pinned, CPU-friendly).
- [ ] 
un_all.sh orchestrating tests ? sweeps ? notebook.
- [ ] Fully implemented SAMD-SS + baselines + sketches.
- [ ] Config-driven experiments covering all claims.
- [ ] rtifacts/ populated via 
un_all.sh.
- [ ] Notebook regenerates every figure/table deterministically.
- [ ] Tests demonstrating correctness + sanity checks.

Failure to satisfy any checkbox blocks acceptance.
